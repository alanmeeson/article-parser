{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a7f86c-065a-4110-82b5-b03d7a710450",
   "metadata": {},
   "source": [
    "# Non Max Suppression\n",
    "\n",
    "**Author:** Alan Meeson <alan@carefullycalculated.co.uk>\n",
    "\n",
    "**Date:** 2023-07-29\n",
    "\n",
    "Adapting the non-max and sub set suppression algorithms from my handwriting repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21183ffc-6c5e-4613-98dd-7f4c0ebed2ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import fitz\n",
    "import torch\n",
    "import torchvision\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import layoutparser as lp\n",
    "import pytesseract\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Dict, Set, Union\n",
    "from pyprojroot import here\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d859522-682d-4499-b107-b08e618e4f4b",
   "metadata": {},
   "source": [
    "## Declare & Apply the analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df416c83-7884-4c47-9866-92e83fb5fd0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = lp.Detectron2LayoutModel(\n",
    "    config_path=os.path.join(here(), 'model', 'config.yaml'), \n",
    "    model_path=os.path.join(here(), 'model', 'model_final.pth'),\n",
    "    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.5], \n",
    "    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3: \"Table\", 4: \"Figure\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2394fe-8c11-4800-8798-04cd69262237",
   "metadata": {},
   "source": [
    "## Load a paper and display a page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5bd98-f4ef-4904-bfe7-613f0d25e25e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paper_pdf = os.path.join(here(), 'data', 'Conditional-level-of-students-t-test.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7692cd-9aae-4748-b258-fc960bcdec06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdf = fitz.open(paper_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccfe703-7b3f-439c-8913-e56a0b1eb643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "page = pdf[0]\n",
    "pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "\n",
    "mode = \"RGBA\" if pix.alpha else \"RGB\"\n",
    "img = Image.frombytes(mode, [pix.width, pix.height], pix.samples)\n",
    "\n",
    "layout = model.detect(img)\n",
    "lp.draw_box(img, layout, box_width=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b4939-a537-4745-9cbf-a75f2f961e7c",
   "metadata": {},
   "source": [
    "## Suppress Non Max Regions\n",
    "\n",
    "There are some instances where we will detect two regions for what is likely the same object.  (See the example below).\n",
    "\n",
    "When this happens we want to take the the box which we have the greatest confidence in.  This is where Non-Max Suppression comes in.  \n",
    "\n",
    "The idea here is to take boxes in order of greatest score and as we do so, we exclude any boxes which significantly overlap with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795c600-172c-4dc3-8877-cb6aa8f40173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(img, [layout[7], layout[8]], box_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb3ae02-5cc7-484e-8786-a7f2c6d4981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-max supression\n",
    "\n",
    "# thresh_iou how much we allow two regions to overlap before we filter them out.\n",
    "thresh_iou = 0.5\n",
    "\n",
    "# Declare the list of regions we're going to keep\n",
    "keep = []\n",
    "\n",
    "candidate_regions = layout.sort(key=lambda x: x.score)\n",
    "while candidate_regions:\n",
    "\n",
    "    # extract and keep the region with highest score\n",
    "    region = candidate_regions.pop()\n",
    "    keep.append(region)\n",
    "\n",
    "    # if we have any remaining candidate regions\n",
    "    if candidate_regions:\n",
    "        \n",
    "        # then filter out the ones which significantly overlap with the current region\n",
    "        # we do this with looking at the ratio of the intersection area over the union area.\n",
    "        candidate_regions = [\n",
    "            x\n",
    "            for x in candidate_regions\n",
    "            if (max(region.intersect(x).area, 0) / region.union(x).area) < thresh_iou\n",
    "        ]\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfc2ca-7c2c-4664-b440-473232c5b125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-30T09:39:16.505365Z",
     "iopub.status.busy": "2023-07-30T09:39:16.505098Z",
     "iopub.status.idle": "2023-07-30T09:39:16.509933Z",
     "shell.execute_reply": "2023-07-30T09:39:16.509338Z",
     "shell.execute_reply.started": "2023-07-30T09:39:16.505344Z"
    }
   },
   "source": [
    "After we apply the above algorithm, we see below that we have eliminated one of the two overlapping sections, retaining the one with the highest score.\n",
    "Worth noting is that we still have two sections where regions are overlapping, but the overlapping srctions are almost entirely contained.  \n",
    "To solve these we look at Sub-section suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596da409-9113-423e-b1ce-bc398b6dedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(img, keep, box_width=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43054d0c-24b4-4af0-9e91-c1df46599570",
   "metadata": {},
   "source": [
    "## Sub-section Suppression\n",
    "\n",
    "Even after we suppress overlapping boxes, we are still often left with situations where we have one box almost entirely as a subset of another. (See below for two examples)\n",
    "\n",
    "In this case, particularly when we are dealing with regions of the same type, we want to take the largest box.\n",
    "\n",
    "Here I have adapted the non-max suppression algorithm to choose the regions with the largest area first, and then exclude those which are within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b832fb12-a9f7-4f81-814f-ac9ac11c2337",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(img, [layout[4], layout[6], layout[5], layout[9]], box_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c3013-73e6-4c71-aa25-7aa97846b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layout = lp.Layout(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dc6f0-326e-42ca-aad7-4dc19f9fd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub-section supression\n",
    "tolerance = 0.1\n",
    "\n",
    "keep = []\n",
    "\n",
    "candidate_regions = sample_layout.sort(key=lambda x: x.area)\n",
    "while candidate_regions:\n",
    "\n",
    "    # extract and keep the region with largest area\n",
    "    region = candidate_regions.pop()\n",
    "    keep.append(region)\n",
    "\n",
    "    # if we have any remaining candidate regions\n",
    "    if candidate_regions:\n",
    "\n",
    "        # We pad the larger region to allow a certain amount of tolerance for\n",
    "        # being not quite entirely overlapping\n",
    "        pad_x = (region.width * tolerance) / 2\n",
    "        pad_y = (region.height * tolerance) / 2\n",
    "        padded_region = region.pad(left=pad_x, right=pad_x, top=pad_y, bottom=pad_y)\n",
    "        \n",
    "        # then filter out the ones which are almost entirely inside the current region\n",
    "        candidate_regions = [\n",
    "            x\n",
    "            for x in candidate_regions\n",
    "            if not x.is_in(padded_region)\n",
    "        ]\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64866877-2596-4faa-b13c-10db48aacd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.draw_box(img, keep, box_width=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff1dfb-7ba8-4abd-951b-edf2ea21d75d",
   "metadata": {},
   "source": [
    "## Bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82ecc8-fd88-4ad3-a514-b266a3637894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(layout: lp.Layout, threshold_iou: float = 0.5) -> lp.Layout:\n",
    "    \"\"\"\n",
    "    Apply non-maximum suppression to avoid detecting too many\n",
    "    overlapping bounding boxes for a given object.\n",
    "\n",
    "    For any group of overlapping regions, the one with the highest score from the\n",
    "    model is kept.\n",
    "    \n",
    "    Args:\n",
    "        layout: (layoutparser.Layout) a Layout generated by layoutparser\n",
    "        threshold_iou: (float) The overlap thresh for suppressing unnecessary boxes.\n",
    "    Returns:\n",
    "        A Layout with the overlapping regions removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Declare the list of regions we're going to keep\n",
    "    keep = []\n",
    "\n",
    "    candidate_regions = layout.sort(key=lambda x: x.score)\n",
    "    while candidate_regions:\n",
    "\n",
    "        # extract and keep the region with highest score\n",
    "        region = candidate_regions.pop()\n",
    "        keep.append(region)\n",
    "    \n",
    "        # if we have any remaining candidate regions\n",
    "        if candidate_regions:\n",
    "            \n",
    "            # then filter out the ones which significantly overlap with the current region\n",
    "            # we do this with looking at the ratio of the intersection area over the union area.\n",
    "            candidate_regions = [\n",
    "                x\n",
    "                for x in candidate_regions\n",
    "                if (max(region.intersect(x).area, 0) / region.union(x).area) < threshold_iou\n",
    "            ]\n",
    "\n",
    "    return lp.Layout(keep)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f3e77-3805-48bc-a7af-8b6b58cae9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_section_suppression(layout: lp.Layout, tolerance: float = 0.1) -> lp.Layout:\n",
    "    \"\"\"\n",
    "    Apply sub-section suppression to avoid detecting too many overlapping bounding \n",
    "    boxes for a given object.  This specifically removes boxes which are (almost) \n",
    "    entirely contained within another box.\n",
    "    \n",
    "    Args:\n",
    "        layout: (layoutparser.Layout) a Layout generated by layoutparser\n",
    "        tolerance: (float) how much of a box can be not within the larger box, and \n",
    "            still count as overlapping.\n",
    "    Returns:\n",
    "        A Layout with the overlapping regions removed.\n",
    "    \"\"\"\n",
    "\n",
    "    keep = []\n",
    "    \n",
    "    candidate_regions = layout.sort(key=lambda x: x.area)\n",
    "    while candidate_regions:\n",
    "    \n",
    "        # extract and keep the region with largest area\n",
    "        region = candidate_regions.pop()\n",
    "        keep.append(region)\n",
    "    \n",
    "        # if we have any remaining candidate regions\n",
    "        if candidate_regions:\n",
    "    \n",
    "            # We pad the larger region to allow a certain amount of tolerance for\n",
    "            # being not quite entirely overlapping\n",
    "            pad_x = (region.width * tolerance) / 2\n",
    "            pad_y = (region.height * tolerance) / 2\n",
    "            padded_region = region.pad(left=pad_x, right=pad_x, top=pad_y, bottom=pad_y)\n",
    "            \n",
    "            # then filter out the ones which are almost entirely inside the current region\n",
    "            candidate_regions = [\n",
    "                x\n",
    "                for x in candidate_regions\n",
    "                if not x.is_in(padded_region)\n",
    "            ]\n",
    "\n",
    "    return lp.Layout(keep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604edece-d0a7-4c0f-878a-839632c3aa78",
   "metadata": {},
   "source": [
    "### Apply to all pages in PDF to get a nice size by size view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293506c-a58a-4612-afdc-64effca3dbed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for page in pdf:\n",
    "    \n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "    \n",
    "    mode = \"RGBA\" if pix.alpha else \"RGB\"\n",
    "    img = Image.frombytes(mode, [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    layout = model.detect(img)\n",
    "    before_img = lp.draw_box(img, layout, box_width=3)\n",
    "\n",
    "    nms_layout = non_max_suppression(layout)\n",
    "    nms_img = lp.draw_box(img, nms_layout, box_width=3)\n",
    "\n",
    "    sss_layout = sub_section_suppression(nms_layout)\n",
    "    sss_img = lp.draw_box(img, sss_layout, box_width=3)\n",
    "\n",
    "    f, axarr = plt.subplots(1,3, figsize=(24,8))\n",
    "    axarr[0].imshow(before_img)\n",
    "    axarr[0].set_axis_off()\n",
    "    axarr[1].imshow(nms_img)\n",
    "    axarr[1].set_axis_off()\n",
    "    axarr[2].imshow(sss_img)\n",
    "    axarr[2].set_axis_off()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
